from llama_index.core.node_parser import HierarchicalNodeParser, get_leaf_nodes
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings
from llama_index.vector_stores.chroma import ChromaVectorStore
from dotenv import load_dotenv
import os, sys
from pathlib import Path
import chromadb

# --- SETUP C∆† B·∫¢N ---
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.append(project_root)

from core import Embedding

load_dotenv()
Settings.embed_model = Embedding()
# L∆∞u √Ω: Settings.chunk_size ·ªü ƒë√¢y ch·ªâ l√† default, Hierarchical s·∫Ω d√πng tham s·ªë ri√™ng b√™n d∆∞·ªõi

crawl_dir = os.environ.get("DATA_CRAWL", "./crawl")
md_dir  = Path(crawl_dir) / "md"
persist_dir = "./chroma_store"
collection_name = "hackathon"
DOCSTORE_DIR = "./docstore_save"
DONE_FILE = md_dir / "done.txt"

# =========================================================
# B∆Ø·ªöC 0: L·ªåC FILE ƒê√É L√ÄM (GI·ªÆ NGUY√äN)
# =========================================================
processed_files = set()
if DONE_FILE.exists():
    with open(DONE_FILE, "r", encoding="utf-8") as f:
        processed_files = {line.strip() for line in f if line.strip()}

print(f"--> ƒê√£ t√¨m th·∫•y {len(processed_files)} file ƒë√£ x·ª≠ l√Ω tr∆∞·ªõc ƒë√≥.")

all_md_files = list(md_dir.glob("*.md"))
new_files_to_process = [f for f in all_md_files if f.name not in processed_files]

if not new_files_to_process:
    print("‚úÖ Kh√¥ng c√≥ file m·ªõi. H·ªá th·ªëng ngh·ªâ!")
    sys.exit(0)

print(f"üöÄ T√¨m th·∫•y {len(new_files_to_process)} file m·ªõi. B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")

# =========================================================
# LOAD DATA
# =========================================================
def clean_file_metadata(file_path):
    return {"file_name": Path(file_path).name}

documents = SimpleDirectoryReader(
    input_files=new_files_to_process, 
    file_metadata=clean_file_metadata
).load_data()

# =========================================================
# B∆Ø·ªöC 1 & 2 G·ªòP L·∫†I: C·∫ÆT TR·ª∞C TI·∫æP (B·ªé MARKDOWN PARSER)
# =========================================================
print("--> ƒêang c·∫•u h√¨nh Hierarchical Node Parser...")

hierarchical_parser = HierarchicalNodeParser.from_defaults(
    chunk_sizes=[1024, 512], # Cha 1024, Con 512
    
    # --- QUAN TR·ªåNG NH·∫§T: CH·ªêNG M·∫§T D·ªÆ LI·ªÜU ---
    # 128 token overlap (~50-70 t·ª´).
    # ƒê·∫£m b·∫£o ƒëo·∫°n cu·ªëi node tr∆∞·ªõc v√† ƒëo·∫°n ƒë·∫ßu node sau gi·ªëng h·ªát nhau.
    # Kh√¥ng bao gi·ªù s·ª£ b·ªã c·∫Øt gi·ªØa ch·ª´ng l√†m m·∫•t nghƒ©a.
    chunk_overlap=128 
)

print("--> ƒêang c·∫Øt nodes t·ª´ documents g·ªëc...")
# Input tr·ª±c ti·∫øp l√† 'documents' (ch·ª©a to√†n b·ªô n·ªôi dung file)
final_nodes = hierarchical_parser.get_nodes_from_documents(documents)

print(f"‚úÖ T·ªïng s·ªë l∆∞·ª£ng nodes (Cha + Con) sau khi c·∫Øt: {len(final_nodes)}")

# =========================================================
# B∆Ø·ªöC 3: L∆ØU TR·ªÆ (GI·ªÆ NGUY√äN)
# =========================================================
leaf_nodes = get_leaf_nodes(final_nodes)

db = chromadb.PersistentClient(path=persist_dir)
chroma_collection = db.get_or_create_collection(collection_name)
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)

if os.path.exists(DOCSTORE_DIR) and os.path.exists(os.path.join(DOCSTORE_DIR, "docstore.json")):
    print("--> Load DocStore c≈©...")
    storage_context = StorageContext.from_defaults(
        persist_dir=DOCSTORE_DIR, 
        vector_store=vector_store
    )
else:
    print("--> T·∫°o DocStore m·ªõi...")
    storage_context = StorageContext.from_defaults(vector_store=vector_store)

storage_context.docstore.add_documents(final_nodes)

print("--> ƒêang embedding v√† l∆∞u v√†o Chroma...")
index = VectorStoreIndex(
    leaf_nodes, 
    storage_context=storage_context,
    show_progress=True 
)

storage_context.persist(persist_dir=DOCSTORE_DIR)
print("‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu th√†nh c√¥ng!")

# =========================================================
# C·∫¨P NH·∫¨T DONE.TXT
# =========================================================
with open(DONE_FILE, "a", encoding="utf-8") as f:
    for file_path in new_files_to_process:
        f.write(f"{file_path.name}\n")

print("Ho√†n t·∫•t!")